{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Opossum Search Documentation Welcome to the Opossum Search documentation. This site provides detailed information about the system's architecture, features, and operational guidelines. Service Availability The service availability documentation describes how the system ensures continuous operation through monitoring, failover mechanisms, and service recovery procedures. Context and Scope Quality Requirements Architecture Constraints Availability Monitoring Error Handling Rate Limiting Logging and Alerts Fallback Mechanisms Testing and Validation Diagrams","title":"Home"},{"location":"#opossum-search-documentation","text":"Welcome to the Opossum Search documentation. This site provides detailed information about the system's architecture, features, and operational guidelines.","title":"Opossum Search Documentation"},{"location":"#service-availability","text":"The service availability documentation describes how the system ensures continuous operation through monitoring, failover mechanisms, and service recovery procedures. Context and Scope Quality Requirements Architecture Constraints Availability Monitoring Error Handling Rate Limiting Logging and Alerts Fallback Mechanisms Testing and Validation Diagrams","title":"Service Availability"},{"location":"service-availability/architecture-constraints/","text":"3. Architecture Constraints 3.1 External Service Dependencies Service Dependency Type Constraint Impact Gemini API Hard dependency for primary path Requires valid API key and network connectivity Service unavailability triggers failover to Ollama Google Cloud Platform Infrastructure for Gemini Subject to Google's maintenance windows and SLAs May cause temporary Gemini unavailability OpenAI API Optional fallback service Rate-limited based on subscription tier Provides additional redundancy if configured 3.2 Local Service Dependencies Service Constraint Impact Ollama Requires local GPU for optimal performance Performance degradation on CPU-only systems Transformers Requires sufficient RAM for model loading Lower capability models used when RAM is limited Python Runtime Version 3.8+ required Application will not start on older Python versions 3.3 Infrastructure Requirements Component Requirement Rationale CPU 4+ cores recommended Needed for concurrent service checks and model inference RAM Minimum 8GB, 16GB recommended Required for local model loading and operation Storage 10GB minimum for application and models Local models require significant storage space Network Reliable internet connection for external APIs Intermittent connectivity will affect Gemini service Docker Optional but recommended for Ollama isolation Simplifies deployment and management of Ollama service 3.4 Operating Environment Constraints Constraint Description Mitigation Firewall Restrictions Corporate firewalls may block API calls to Google Configure proxy settings or use local services only Rate Limits Gemini API has strict rate limits Implement request queueing and smart routing Offline Operation Must function with degraded capabilities when offline Ensure Transformers models are pre-downloaded Cross-Platform Support Must run on Windows, macOS, and Linux Abstract platform-specific code and test on all platforms 3.5 Technical Debt and Limitations Limitation Description Future Improvement Manual Failover Recovery System does not automatically recover preferred services Implement automatic service recovery detection Limited API Compatibility Different model providers have different APIs Create abstraction layer to normalize responses Fixed Check Interval Service checks occur at fixed intervals Implement adaptive check intervals based on service stability Missing Health Metrics Only binary up/down status tracked Add response time and error rate tracking Circuit Breaker Patterns Basic implementation of failure detection Implement comprehensive circuit breaker patterns","title":"Architecture Constraints"},{"location":"service-availability/architecture-constraints/#3-architecture-constraints","text":"","title":"3. Architecture Constraints"},{"location":"service-availability/architecture-constraints/#31-external-service-dependencies","text":"Service Dependency Type Constraint Impact Gemini API Hard dependency for primary path Requires valid API key and network connectivity Service unavailability triggers failover to Ollama Google Cloud Platform Infrastructure for Gemini Subject to Google's maintenance windows and SLAs May cause temporary Gemini unavailability OpenAI API Optional fallback service Rate-limited based on subscription tier Provides additional redundancy if configured","title":"3.1 External Service Dependencies"},{"location":"service-availability/architecture-constraints/#32-local-service-dependencies","text":"Service Constraint Impact Ollama Requires local GPU for optimal performance Performance degradation on CPU-only systems Transformers Requires sufficient RAM for model loading Lower capability models used when RAM is limited Python Runtime Version 3.8+ required Application will not start on older Python versions","title":"3.2 Local Service Dependencies"},{"location":"service-availability/architecture-constraints/#33-infrastructure-requirements","text":"Component Requirement Rationale CPU 4+ cores recommended Needed for concurrent service checks and model inference RAM Minimum 8GB, 16GB recommended Required for local model loading and operation Storage 10GB minimum for application and models Local models require significant storage space Network Reliable internet connection for external APIs Intermittent connectivity will affect Gemini service Docker Optional but recommended for Ollama isolation Simplifies deployment and management of Ollama service","title":"3.3 Infrastructure Requirements"},{"location":"service-availability/architecture-constraints/#34-operating-environment-constraints","text":"Constraint Description Mitigation Firewall Restrictions Corporate firewalls may block API calls to Google Configure proxy settings or use local services only Rate Limits Gemini API has strict rate limits Implement request queueing and smart routing Offline Operation Must function with degraded capabilities when offline Ensure Transformers models are pre-downloaded Cross-Platform Support Must run on Windows, macOS, and Linux Abstract platform-specific code and test on all platforms","title":"3.4 Operating Environment Constraints"},{"location":"service-availability/architecture-constraints/#35-technical-debt-and-limitations","text":"Limitation Description Future Improvement Manual Failover Recovery System does not automatically recover preferred services Implement automatic service recovery detection Limited API Compatibility Different model providers have different APIs Create abstraction layer to normalize responses Fixed Check Interval Service checks occur at fixed intervals Implement adaptive check intervals based on service stability Missing Health Metrics Only binary up/down status tracked Add response time and error rate tracking Circuit Breaker Patterns Basic implementation of failure detection Implement comprehensive circuit breaker patterns","title":"3.5 Technical Debt and Limitations"},{"location":"service-availability/availability-monitoring/","text":"4. Availability Monitoring 4.1 Monitoring Strategy Component Strategy Implementation Service Availability Active polling Asynchronous health checks to all services Rate Limit Tracking Counter-based In-memory tracking with time-based resets Status Changes Event-based Status change detection and logging Failure Detection Exception handling Request timeouts and error catching 4.2 Check Frequency and Scheduling Service Check Frequency Caching Duration Trigger Mechanism Gemini API Every 30 seconds (max) 30 seconds On-demand with caching Ollama Every 30 seconds (max) 30 seconds On-demand with caching Transformers Every 30 seconds (max) 30 seconds On-demand with caching All Services On application startup N/A Initialization check 4.3 Metrics Collection Metric Collection Method Storage Purpose Service Status Boolean availability flag In-memory dictionary Service selection Last Check Timestamp Datetime object In-memory dictionary Throttling checks Gemini Daily Usage Counter with daily reset In-memory counter Rate limit compliance Gemini Per-Minute Usage Counter with minute reset In-memory counter Rate limit compliance Service Transitions Event logging Application logs Diagnostics and reporting 4.4 Monitoring Tools Tool Purpose Integration Standard Logging Record availability events and transitions Python logging module Health Check API Internal HTTP endpoint for status monitoring Flask route handler Exception Tracking Capture and report service check failures Try-except blocks with logging Status Dashboard Visual representation of service availability Admin interface (planned) 4.5 Implementation Details The monitoring system uses concurrent asynchronous checks to efficiently assess service availability: class ServiceAvailability: def __init__(self): self.services_status = { \"gemini\": {\"available\": False, \"last_checked\": None}, \"ollama\": {\"available\": False, \"last_checked\": None}, \"transformers\": {\"available\": False, \"last_checked\": None} } self.check_interval = 30 # seconds async def check_all_services(self): \"\"\"Check availability of all configured services\"\"\" logger.debug(\"Beginning availability check for all services\") # Run all checks concurrently await asyncio.gather( self.check_ollama_availability(), self.check_gemini_availability(), self.check_transformers_availability() ) async def check_gemini_availability(self): \"\"\"Check if Gemini API is available\"\"\" try: # Implement a lightweight request to Gemini API # Record result in services_status dictionary current_time = datetime.now() if self.services_status[\"gemini\"][\"last_checked\"] is None or \\ (current_time - self.services_status[\"gemini\"][\"last_checked\"]).seconds > self.check_interval: # Perform actual check here self.services_status[\"gemini\"][\"available\"] = True # Set based on check result self.services_status[\"gemini\"][\"last_checked\"] = current_time logger.info(\"Gemini API is available\") except Exception as e: self.services_status[\"gemini\"][\"available\"] = False self.services_status[\"gemini\"][\"last_checked\"] = datetime.now() logger.error(f\"Gemini API check failed: {str(e)}\") # Similar methods for check_ollama_availability and check_transformers_availability 4.6 Availability Reporting Report Frequency Contents Distribution Status Change Alerts Real-time Service, previous status, new status, reason Logs Availability Summary Daily Uptime percentages, outage periods, failover counts Logs, email (planned) Rate Limit Reports Daily API usage statistics, remaining quota Logs Service Health Check On-demand Current status of all services API endpoint (planned)","title":"Availability Monitoring"},{"location":"service-availability/availability-monitoring/#4-availability-monitoring","text":"","title":"4. Availability Monitoring"},{"location":"service-availability/availability-monitoring/#41-monitoring-strategy","text":"Component Strategy Implementation Service Availability Active polling Asynchronous health checks to all services Rate Limit Tracking Counter-based In-memory tracking with time-based resets Status Changes Event-based Status change detection and logging Failure Detection Exception handling Request timeouts and error catching","title":"4.1 Monitoring Strategy"},{"location":"service-availability/availability-monitoring/#42-check-frequency-and-scheduling","text":"Service Check Frequency Caching Duration Trigger Mechanism Gemini API Every 30 seconds (max) 30 seconds On-demand with caching Ollama Every 30 seconds (max) 30 seconds On-demand with caching Transformers Every 30 seconds (max) 30 seconds On-demand with caching All Services On application startup N/A Initialization check","title":"4.2 Check Frequency and Scheduling"},{"location":"service-availability/availability-monitoring/#43-metrics-collection","text":"Metric Collection Method Storage Purpose Service Status Boolean availability flag In-memory dictionary Service selection Last Check Timestamp Datetime object In-memory dictionary Throttling checks Gemini Daily Usage Counter with daily reset In-memory counter Rate limit compliance Gemini Per-Minute Usage Counter with minute reset In-memory counter Rate limit compliance Service Transitions Event logging Application logs Diagnostics and reporting","title":"4.3 Metrics Collection"},{"location":"service-availability/availability-monitoring/#44-monitoring-tools","text":"Tool Purpose Integration Standard Logging Record availability events and transitions Python logging module Health Check API Internal HTTP endpoint for status monitoring Flask route handler Exception Tracking Capture and report service check failures Try-except blocks with logging Status Dashboard Visual representation of service availability Admin interface (planned)","title":"4.4 Monitoring Tools"},{"location":"service-availability/availability-monitoring/#45-implementation-details","text":"The monitoring system uses concurrent asynchronous checks to efficiently assess service availability: class ServiceAvailability: def __init__(self): self.services_status = { \"gemini\": {\"available\": False, \"last_checked\": None}, \"ollama\": {\"available\": False, \"last_checked\": None}, \"transformers\": {\"available\": False, \"last_checked\": None} } self.check_interval = 30 # seconds async def check_all_services(self): \"\"\"Check availability of all configured services\"\"\" logger.debug(\"Beginning availability check for all services\") # Run all checks concurrently await asyncio.gather( self.check_ollama_availability(), self.check_gemini_availability(), self.check_transformers_availability() ) async def check_gemini_availability(self): \"\"\"Check if Gemini API is available\"\"\" try: # Implement a lightweight request to Gemini API # Record result in services_status dictionary current_time = datetime.now() if self.services_status[\"gemini\"][\"last_checked\"] is None or \\ (current_time - self.services_status[\"gemini\"][\"last_checked\"]).seconds > self.check_interval: # Perform actual check here self.services_status[\"gemini\"][\"available\"] = True # Set based on check result self.services_status[\"gemini\"][\"last_checked\"] = current_time logger.info(\"Gemini API is available\") except Exception as e: self.services_status[\"gemini\"][\"available\"] = False self.services_status[\"gemini\"][\"last_checked\"] = datetime.now() logger.error(f\"Gemini API check failed: {str(e)}\") # Similar methods for check_ollama_availability and check_transformers_availability","title":"4.5 Implementation Details"},{"location":"service-availability/availability-monitoring/#46-availability-reporting","text":"Report Frequency Contents Distribution Status Change Alerts Real-time Service, previous status, new status, reason Logs Availability Summary Daily Uptime percentages, outage periods, failover counts Logs, email (planned) Rate Limit Reports Daily API usage statistics, remaining quota Logs Service Health Check On-demand Current status of all services API endpoint (planned)","title":"4.6 Availability Reporting"},{"location":"service-availability/context-and-scope/","text":"1. Context and Scope 1.1 Overview This document describes the service availability monitoring system implemented for the Opossum Search application. The system monitors the availability of multiple AI model backends, manages rate limits, and provides automatic failover to ensure continuous operation. 1.2 Services in Scope The following services are monitored for availability: Service Type Purpose Availability Mechanism Gemini External API High-capability AI models with API-based access API key validation and rate limit monitoring Ollama Local service Self-hosted AI models with REST API Connection health checking Transformers Local library Fallback for offline operation Always assumed available (local) 1.3 Critical Paths The application depends on at least one service being available to respond to user queries. The dependency chain is: Primary Path : Gemini API (when available and suitable for query type) Secondary Path : Ollama service (when available and suitable for query type) Fallback Path : Transformers models (always available, used when other services fail) 1.4 System Boundaries The availability system: Monitors : All AI model service endpoints Records : Usage statistics for rate-limited services Logs : Service status changes and availability events Does Not : Handle network configuration or service deployment 1.5 Stakeholders Stakeholder Interest in Service Availability End Users Uninterrupted access to AI functionality Operations Team Monitoring service health and diagnostics Developers Understanding fallback behavior and service dependencies 1.6 External Interfaces Gemini API : Google Cloud API with rate limits and authentication Ollama REST API : Local service providing model inference Transformers Library : Local Python library for model inference 1.7 Technical Context The service availability system is implemented as a component in the model backend selection process. It: Performs regular health checks (maximum once per 30 seconds per service) Runs checks concurrently to minimize impact on performance Influences model selection based on real-time availability Provides status information for logging and diagnostics","title":"Context and Scope"},{"location":"service-availability/context-and-scope/#1-context-and-scope","text":"","title":"1. Context and Scope"},{"location":"service-availability/context-and-scope/#11-overview","text":"This document describes the service availability monitoring system implemented for the Opossum Search application. The system monitors the availability of multiple AI model backends, manages rate limits, and provides automatic failover to ensure continuous operation.","title":"1.1 Overview"},{"location":"service-availability/context-and-scope/#12-services-in-scope","text":"The following services are monitored for availability: Service Type Purpose Availability Mechanism Gemini External API High-capability AI models with API-based access API key validation and rate limit monitoring Ollama Local service Self-hosted AI models with REST API Connection health checking Transformers Local library Fallback for offline operation Always assumed available (local)","title":"1.2 Services in Scope"},{"location":"service-availability/context-and-scope/#13-critical-paths","text":"The application depends on at least one service being available to respond to user queries. The dependency chain is: Primary Path : Gemini API (when available and suitable for query type) Secondary Path : Ollama service (when available and suitable for query type) Fallback Path : Transformers models (always available, used when other services fail)","title":"1.3 Critical Paths"},{"location":"service-availability/context-and-scope/#14-system-boundaries","text":"The availability system: Monitors : All AI model service endpoints Records : Usage statistics for rate-limited services Logs : Service status changes and availability events Does Not : Handle network configuration or service deployment","title":"1.4 System Boundaries"},{"location":"service-availability/context-and-scope/#15-stakeholders","text":"Stakeholder Interest in Service Availability End Users Uninterrupted access to AI functionality Operations Team Monitoring service health and diagnostics Developers Understanding fallback behavior and service dependencies","title":"1.5 Stakeholders"},{"location":"service-availability/context-and-scope/#16-external-interfaces","text":"Gemini API : Google Cloud API with rate limits and authentication Ollama REST API : Local service providing model inference Transformers Library : Local Python library for model inference","title":"1.6 External Interfaces"},{"location":"service-availability/context-and-scope/#17-technical-context","text":"The service availability system is implemented as a component in the model backend selection process. It: Performs regular health checks (maximum once per 30 seconds per service) Runs checks concurrently to minimize impact on performance Influences model selection based on real-time availability Provides status information for logging and diagnostics","title":"1.7 Technical Context"},{"location":"service-availability/fallback-mechanisms/","text":"8. Fallback Mechanisms 8.1 Fallback Hierarchy Priority Service Type Capabilities Limitations 1 (Primary) Gemini API External API Full model capabilities, high intelligence Rate limited, requires internet 2 (Secondary) Ollama Local service Good capabilities, custom models Requires GPU for performance, local deployment 3 (Tertiary) Transformers Local library Basic capabilities, offline operation Higher latency, limited model size 4 (Emergency) Client-side JavaScript Basic scripted responses Very limited capabilities, no real AI 8.2 Activation Conditions Fallback Path Activation Conditions Detection Method Gemini \u2192 Ollama API unavailable, rate limit exceeded, authentication failure HTTP errors (429, 401, 403, 5xx), timeout Ollama \u2192 Transformers Connection failure, resource exhaustion Socket errors, initialization failure Server \u2192 Client All server services unavailable, network failure Multiple failed API requests Any \u2192 Preferred Service Previously unavailable service now available Periodic health checks 8.3 Fallback Implementation class ServiceRouter: def __init__(self, availability_manager): self.availability_manager = availability_manager async def route_request(self, user_request): \"\"\"Route request to best available service\"\"\" services = await self.availability_manager.get_available_services() if \"gemini\" in services and not self.will_exceed_rate_limit(user_request): return await self.process_with_gemini(user_request) elif \"ollama\" in services: return await self.process_with_ollama(user_request) elif \"transformers\" in services: return await self.process_with_transformers(user_request) else: return { \"response\": \"Sorry, no AI services are currently available.\", \"fallback_used\": \"none\", \"service_status\": \"unavailable\" } 8.4 Client-Side Fallback The frontend implements a JavaScript-based fallback that simulates basic responses when server services are unavailable: // Excerpt from client-side fallback function getBotResponse(userMessage) { // Fallback simulation function userMessage = userMessage.toLowerCase().trim(); let botMessage = \"\"; switch (conversationStage) { case \"greeting\": if (userMessage.includes(\"hi\") || userMessage.includes(\"hello\")) { botMessage = \"Greetings! I am your Opossum Information Assistant. How can I help you?\"; conversationStage = \"initial_query\"; } else { botMessage = \"Sorry, I didn't catch that. Perhaps start with a friendly 'Hello'?\"; } break; // Additional conversation stages and responses... default: botMessage = \"I'm in simulation mode. Please ask something about opossums.\"; } return botMessage; } 8.5 Capability Degradation Service Capability Level Features Available Features Limited Gemini API Full Complete AI capabilities, image analysis None Ollama High Near-complete AI capabilities Some specialized models, slower image processing Transformers Medium Basic Q&A, text completion Complex reasoning, image processing Client-side Minimal Scripted responses only All AI capabilities 8.6 User Experience During Fallback Fallback Scenario User Notification Experience Impact Gemini \u2192 Ollama \"Using alternative AI service\" Minimal impact, slight latency increase Ollama \u2192 Transformers \"Using simplified model\" Noticeable capability reduction Server \u2192 Client \"Using simplified mode temporarily\" Severely limited capabilities Temporary Outage Loading indicator, retry message Brief delay before fallback activates 8.7 Recovery Mechanisms Recovery Type Detection Implementation User Experience Automatic Periodic health checks Service switching when preferred service returns Seamless transition to better service Semi-Automatic Service status monitoring Manual approval of service transition Brief service interruption Manual Administrator intervention Configuration update and service restart Temporary unavailability during restart 8.8 Fallback Testing Test Type Frequency Methodology Success Criteria Controlled Outage Weekly Simulate API unavailability Successful transition to fallback within 2s Rate Limit Test Monthly Generate high request volume Preemptive fallback before limit reached Complete Failure Quarterly Simulate all service unavailability Client-side fallback activated within 10s Recovery Test Monthly Restore services after simulated outage Return to primary service within 30s","title":"Fallback Mechanisms"},{"location":"service-availability/fallback-mechanisms/#8-fallback-mechanisms","text":"","title":"8. Fallback Mechanisms"},{"location":"service-availability/fallback-mechanisms/#81-fallback-hierarchy","text":"Priority Service Type Capabilities Limitations 1 (Primary) Gemini API External API Full model capabilities, high intelligence Rate limited, requires internet 2 (Secondary) Ollama Local service Good capabilities, custom models Requires GPU for performance, local deployment 3 (Tertiary) Transformers Local library Basic capabilities, offline operation Higher latency, limited model size 4 (Emergency) Client-side JavaScript Basic scripted responses Very limited capabilities, no real AI","title":"8.1 Fallback Hierarchy"},{"location":"service-availability/fallback-mechanisms/#82-activation-conditions","text":"Fallback Path Activation Conditions Detection Method Gemini \u2192 Ollama API unavailable, rate limit exceeded, authentication failure HTTP errors (429, 401, 403, 5xx), timeout Ollama \u2192 Transformers Connection failure, resource exhaustion Socket errors, initialization failure Server \u2192 Client All server services unavailable, network failure Multiple failed API requests Any \u2192 Preferred Service Previously unavailable service now available Periodic health checks","title":"8.2 Activation Conditions"},{"location":"service-availability/fallback-mechanisms/#83-fallback-implementation","text":"class ServiceRouter: def __init__(self, availability_manager): self.availability_manager = availability_manager async def route_request(self, user_request): \"\"\"Route request to best available service\"\"\" services = await self.availability_manager.get_available_services() if \"gemini\" in services and not self.will_exceed_rate_limit(user_request): return await self.process_with_gemini(user_request) elif \"ollama\" in services: return await self.process_with_ollama(user_request) elif \"transformers\" in services: return await self.process_with_transformers(user_request) else: return { \"response\": \"Sorry, no AI services are currently available.\", \"fallback_used\": \"none\", \"service_status\": \"unavailable\" }","title":"8.3 Fallback Implementation"},{"location":"service-availability/fallback-mechanisms/#84-client-side-fallback","text":"The frontend implements a JavaScript-based fallback that simulates basic responses when server services are unavailable: // Excerpt from client-side fallback function getBotResponse(userMessage) { // Fallback simulation function userMessage = userMessage.toLowerCase().trim(); let botMessage = \"\"; switch (conversationStage) { case \"greeting\": if (userMessage.includes(\"hi\") || userMessage.includes(\"hello\")) { botMessage = \"Greetings! I am your Opossum Information Assistant. How can I help you?\"; conversationStage = \"initial_query\"; } else { botMessage = \"Sorry, I didn't catch that. Perhaps start with a friendly 'Hello'?\"; } break; // Additional conversation stages and responses... default: botMessage = \"I'm in simulation mode. Please ask something about opossums.\"; } return botMessage; }","title":"8.4 Client-Side Fallback"},{"location":"service-availability/fallback-mechanisms/#85-capability-degradation","text":"Service Capability Level Features Available Features Limited Gemini API Full Complete AI capabilities, image analysis None Ollama High Near-complete AI capabilities Some specialized models, slower image processing Transformers Medium Basic Q&A, text completion Complex reasoning, image processing Client-side Minimal Scripted responses only All AI capabilities","title":"8.5 Capability Degradation"},{"location":"service-availability/fallback-mechanisms/#86-user-experience-during-fallback","text":"Fallback Scenario User Notification Experience Impact Gemini \u2192 Ollama \"Using alternative AI service\" Minimal impact, slight latency increase Ollama \u2192 Transformers \"Using simplified model\" Noticeable capability reduction Server \u2192 Client \"Using simplified mode temporarily\" Severely limited capabilities Temporary Outage Loading indicator, retry message Brief delay before fallback activates","title":"8.6 User Experience During Fallback"},{"location":"service-availability/fallback-mechanisms/#87-recovery-mechanisms","text":"Recovery Type Detection Implementation User Experience Automatic Periodic health checks Service switching when preferred service returns Seamless transition to better service Semi-Automatic Service status monitoring Manual approval of service transition Brief service interruption Manual Administrator intervention Configuration update and service restart Temporary unavailability during restart","title":"8.7 Recovery Mechanisms"},{"location":"service-availability/fallback-mechanisms/#88-fallback-testing","text":"Test Type Frequency Methodology Success Criteria Controlled Outage Weekly Simulate API unavailability Successful transition to fallback within 2s Rate Limit Test Monthly Generate high request volume Preemptive fallback before limit reached Complete Failure Quarterly Simulate all service unavailability Client-side fallback activated within 10s Recovery Test Monthly Restore services after simulated outage Return to primary service within 30s","title":"8.8 Fallback Testing"},{"location":"service-availability/log-alerts/","text":"7. Logging and Alerts 7.1 Logging Strategy Log Category Purpose Implementation Retention Service Status Track service availability changes Structured JSON logs 30 days Rate Limit Monitor API usage against quotas Counter logs with timestamps 90 days Error Events Record service failures and exceptions Exception details with stack traces 14 days Recovery Actions Document automatic recovery attempts Action logs with outcomes 14 days Performance Metrics Track response times and latency Time-series metrics 180 days 7.2 Log Levels Level Usage Example DEBUG Detailed diagnostic information \"Checking Gemini API availability\" INFO Normal operational events \"Service status changed: Gemini API now AVAILABLE\" WARNING Non-critical issues \"Approaching rate limit (85% used)\" ERROR Runtime errors, failed operations \"Connection to Ollama failed: Connection refused\" CRITICAL System-wide failures \"All services unavailable, switching to offline mode\" 7.3 Logging Implementation import logging import json from datetime import datetime # Configure logger logger = logging.getLogger(\"service_availability\") logger.setLevel(logging.INFO) # File handler file_handler = logging.FileHandler(\"service_availability.log\") file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')) logger.addHandler(file_handler) class ServiceLogger: @staticmethod def log_status_change(service_name, old_status, new_status, reason=None): \"\"\"Log a service status change with structured data\"\"\" log_data = { \"event_type\": \"status_change\", \"timestamp\": datetime.now().isoformat(), \"service\": service_name, \"old_status\": old_status, \"new_status\": new_status, \"reason\": reason } logger.info(f\"Service status changed: {service_name} now {new_status}\", extra={\"data\": json.dumps(log_data)}) # Critical service unavailability triggers higher level log if new_status == \"UNAVAILABLE\" and service_name in [\"Gemini API\", \"Ollama\"]: logger.warning(f\"Critical service {service_name} is now unavailable. Reason: {reason}\") @staticmethod def log_rate_limit(service_name, limit_type, current_usage, total_limit): \"\"\"Log rate limit information\"\"\" usage_percent = (current_usage / total_limit) * 100 log_level = logging.INFO if usage_percent > 95: log_level = logging.ERROR elif usage_percent > 80: log_level = logging.WARNING log_data = { \"event_type\": \"rate_limit\", \"service\": service_name, \"limit_type\": limit_type, \"usage\": current_usage, \"limit\": total_limit, \"percent\": usage_percent } logger.log(log_level, f\"{service_name} {limit_type} usage: {usage_percent:.1f}% ({current_usage}/{total_limit})\", extra={\"data\": json.dumps(log_data)}) 7.4 Alert Triggers Trigger Condition Severity Response Time Service Unavailable Any primary service becomes unavailable High Immediate Rate Limit Threshold >95% of minute or daily quota consumed Medium < 5 minutes Recovery Failure 3+ consecutive failed recovery attempts High Immediate Multiple Failovers >5 failovers in 24 hours Medium < 1 hour All Services Down No available AI services Critical Immediate 7.5 Notification Channels Channel Target Audience Alert Types Implementation Application Logs Developers All events Structured logging with context Email Alerts Operations Team High & Critical events SMTP integration UI Notifications End Users Service degradation Browser notifications via frontend Status Dashboard All stakeholders Service status, outages Real-time web dashboard Slack Channel Operations & Development Medium+ severity Webhook integration 7.6 Alert Templates Alert Type Template Channel Service Down \"[ALERT] {service_name} is DOWN. Reason: {reason}. Failover to {fallback_service} initiated.\" Email, Slack Rate Limit \"[WARNING] {service_name} approaching rate limit: {usage_percent}% of {limit_type} used.\" Logs, Slack Recovery Success \"[INFO] {service_name} successfully recovered after {downtime} minutes of unavailability.\" Logs Client Notification \"Using alternative AI service due to temporary unavailability. Some features may be limited.\" UI 7.7 Log Analysis Analysis Type Purpose Tools Frequency Availability Reporting Calculate uptime percentages Custom scripts Daily Error Pattern Detection Identify recurring issues Log parsing Weekly Rate Limit Forecasting Predict quota exhaustion Time-series analysis Hourly Service Quality Metrics Track performance degradation Dashboards Real-time Audit Trail Security and compliance review Log archiving Monthly","title":"Logging and Alerts"},{"location":"service-availability/log-alerts/#7-logging-and-alerts","text":"","title":"7. Logging and Alerts"},{"location":"service-availability/log-alerts/#71-logging-strategy","text":"Log Category Purpose Implementation Retention Service Status Track service availability changes Structured JSON logs 30 days Rate Limit Monitor API usage against quotas Counter logs with timestamps 90 days Error Events Record service failures and exceptions Exception details with stack traces 14 days Recovery Actions Document automatic recovery attempts Action logs with outcomes 14 days Performance Metrics Track response times and latency Time-series metrics 180 days","title":"7.1 Logging Strategy"},{"location":"service-availability/log-alerts/#72-log-levels","text":"Level Usage Example DEBUG Detailed diagnostic information \"Checking Gemini API availability\" INFO Normal operational events \"Service status changed: Gemini API now AVAILABLE\" WARNING Non-critical issues \"Approaching rate limit (85% used)\" ERROR Runtime errors, failed operations \"Connection to Ollama failed: Connection refused\" CRITICAL System-wide failures \"All services unavailable, switching to offline mode\"","title":"7.2 Log Levels"},{"location":"service-availability/log-alerts/#73-logging-implementation","text":"import logging import json from datetime import datetime # Configure logger logger = logging.getLogger(\"service_availability\") logger.setLevel(logging.INFO) # File handler file_handler = logging.FileHandler(\"service_availability.log\") file_handler.setFormatter(logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')) logger.addHandler(file_handler) class ServiceLogger: @staticmethod def log_status_change(service_name, old_status, new_status, reason=None): \"\"\"Log a service status change with structured data\"\"\" log_data = { \"event_type\": \"status_change\", \"timestamp\": datetime.now().isoformat(), \"service\": service_name, \"old_status\": old_status, \"new_status\": new_status, \"reason\": reason } logger.info(f\"Service status changed: {service_name} now {new_status}\", extra={\"data\": json.dumps(log_data)}) # Critical service unavailability triggers higher level log if new_status == \"UNAVAILABLE\" and service_name in [\"Gemini API\", \"Ollama\"]: logger.warning(f\"Critical service {service_name} is now unavailable. Reason: {reason}\") @staticmethod def log_rate_limit(service_name, limit_type, current_usage, total_limit): \"\"\"Log rate limit information\"\"\" usage_percent = (current_usage / total_limit) * 100 log_level = logging.INFO if usage_percent > 95: log_level = logging.ERROR elif usage_percent > 80: log_level = logging.WARNING log_data = { \"event_type\": \"rate_limit\", \"service\": service_name, \"limit_type\": limit_type, \"usage\": current_usage, \"limit\": total_limit, \"percent\": usage_percent } logger.log(log_level, f\"{service_name} {limit_type} usage: {usage_percent:.1f}% ({current_usage}/{total_limit})\", extra={\"data\": json.dumps(log_data)})","title":"7.3 Logging Implementation"},{"location":"service-availability/log-alerts/#74-alert-triggers","text":"Trigger Condition Severity Response Time Service Unavailable Any primary service becomes unavailable High Immediate Rate Limit Threshold >95% of minute or daily quota consumed Medium < 5 minutes Recovery Failure 3+ consecutive failed recovery attempts High Immediate Multiple Failovers >5 failovers in 24 hours Medium < 1 hour All Services Down No available AI services Critical Immediate","title":"7.4 Alert Triggers"},{"location":"service-availability/log-alerts/#75-notification-channels","text":"Channel Target Audience Alert Types Implementation Application Logs Developers All events Structured logging with context Email Alerts Operations Team High & Critical events SMTP integration UI Notifications End Users Service degradation Browser notifications via frontend Status Dashboard All stakeholders Service status, outages Real-time web dashboard Slack Channel Operations & Development Medium+ severity Webhook integration","title":"7.5 Notification Channels"},{"location":"service-availability/log-alerts/#76-alert-templates","text":"Alert Type Template Channel Service Down \"[ALERT] {service_name} is DOWN. Reason: {reason}. Failover to {fallback_service} initiated.\" Email, Slack Rate Limit \"[WARNING] {service_name} approaching rate limit: {usage_percent}% of {limit_type} used.\" Logs, Slack Recovery Success \"[INFO] {service_name} successfully recovered after {downtime} minutes of unavailability.\" Logs Client Notification \"Using alternative AI service due to temporary unavailability. Some features may be limited.\" UI","title":"7.6 Alert Templates"},{"location":"service-availability/log-alerts/#77-log-analysis","text":"Analysis Type Purpose Tools Frequency Availability Reporting Calculate uptime percentages Custom scripts Daily Error Pattern Detection Identify recurring issues Log parsing Weekly Rate Limit Forecasting Predict quota exhaustion Time-series analysis Hourly Service Quality Metrics Track performance degradation Dashboards Real-time Audit Trail Security and compliance review Log archiving Monthly","title":"7.7 Log Analysis"},{"location":"service-availability/processing-diagrams/","text":"10. Diagrams and Visuals 10.1 System Architecture Diagram flowchart TD Client[\"Client Application\"] Router[\"Service Router\"] GeminiAPI[\"Gemini API\\n(External)\"] Ollama[\"Ollama\\n(Local API)\"] Transformers[\"Transformers\\n(Local Lib)\"] Monitoring[\"Availability Monitoring System\"] Client --> Router Router --> GeminiAPI Router --> Ollama Router --> Transformers GeminiAPI & Ollama & Transformers --> Monitoring 10.2 Service Monitoring Flowchart flowchart TD Start[\"Start Application\"] --> CheckInterval[\"Check Interval Reached?\"] CheckInterval --> CheckService[\"Check Service Availability\"] CheckService --> UpdateCache[\"Update Cache\"] UpdateCache --> StatusChanged[\"Status Changed?\"] StatusChanged -- Yes --> StatusEvent[\"Status Change Event\"] StatusEvent --> UpdateLogs[\"Update Logs & Send Alerts\"] StatusChanged -- No --> Wait[\"Wait for Next Check\"] 10.3 Failover Process Diagram flowchart TD Request[\"Request Received\"] --> ServiceAvailable[\"Service Available?\"] ServiceAvailable -- Yes --> RateLimited[\"Service Rate-Limited?\"] ServiceAvailable -- No --> TryNext[\"Try Next Service\"] RateLimited -- No --> ProcessPrimary[\"Process with Primary Service\"] TryNext --> AnyAvailable[\"Any Service Available?\"] AnyAvailable -- No --> ReturnError[\"Return Error\\nUse Client Fallback\"] AnyAvailable -- Yes --> ProcessAvailable[\"Process with\\nAvailable Service\"] 10.4 Rate Limit Monitoring Diagram flowchart TD TrackAPI[\"Track API Request\"] --> ResetPeriod[\"Reset Period Elapsed?\"] ResetPeriod -- Yes --> ResetCounters[\"Reset Counters\"] ResetCounters --> IncrementCounters[\"Increment Counters\"] TrackAPI --> IncrementCounters IncrementCounters --> ApproachingLimit[\"Approaching Limit?\"] ApproachingLimit -- Yes --> LogWarning[\"Log Warning\\nPrepare Fallback\"] ApproachingLimit -- No --> ContinueNormal[\"Continue Normal Operation\"] 10.5 Recovery Detection Process flowchart TD Unavailable[\"Service Unavailable\"] --> HealthCheck[\"Periodic Health Check\"] HealthCheck --> Recovered[\"Service Recovered?\"] Recovered -- No --> ContinueFallback[\"Continue Using Fallback\"] Recovered -- Yes --> LogRecovery[\"Log Recovery\\nUpdate Status\"] LogRecovery --> ResumePreferred[\"Resume Using Preferred Service\"] 10.6 User Experience Flow flowchart TD UserQuery[\"User Submits Query\"] --> FrontendProcess[\"Frontend Processes Input\"] FrontendProcess --> APIRequest[\"API Request to Server\"] APIRequest --> ServerAvailable[\"Server Available?\"] ServerAvailable -- No --> ClientFallback[\"Client-side Fallback Activated\"] ClientFallback --> ShowError[\"Show Error Message with Limited Mode\"] ServerAvailable -- Yes --> UsingFallback[\"Service Using Fallback?\"] UsingFallback -- Yes --> NotifyUser[\"Notify User of Service Limitations\"] UsingFallback -- No --> NormalResponse[\"Normal Response Processing\"] 10.7 C4 Context Diagram C4Context title System Context diagram for Opossum Search Person(user, \"User\", \"A user of the Opossum Search system\") Enterprise_Boundary(b0, \"Opossum Search System\") { System(searchSystem, \"Opossum Search System\", \"Provides search functionality with multiple model providers\") System_Ext(geminiAPI, \"Gemini API\", \"External large language model provider\") System_Ext(ollamaSystem, \"Ollama\", \"Local large language model hosting\") System_Ext(transformersLib, \"Transformers\", \"Local machine learning library\") } Rel(user, searchSystem, \"Submits search queries to\") Rel(searchSystem, geminiAPI, \"Uses for processing when available\") Rel(searchSystem, ollamaSystem, \"Falls back to when Gemini is unavailable\") Rel(searchSystem, transformersLib, \"Uses as final fallback option\")","title":"Diagrams"},{"location":"service-availability/processing-diagrams/#10-diagrams-and-visuals","text":"","title":"10. Diagrams and Visuals"},{"location":"service-availability/processing-diagrams/#101-system-architecture-diagram","text":"flowchart TD Client[\"Client Application\"] Router[\"Service Router\"] GeminiAPI[\"Gemini API\\n(External)\"] Ollama[\"Ollama\\n(Local API)\"] Transformers[\"Transformers\\n(Local Lib)\"] Monitoring[\"Availability Monitoring System\"] Client --> Router Router --> GeminiAPI Router --> Ollama Router --> Transformers GeminiAPI & Ollama & Transformers --> Monitoring","title":"10.1 System Architecture Diagram"},{"location":"service-availability/processing-diagrams/#102-service-monitoring-flowchart","text":"flowchart TD Start[\"Start Application\"] --> CheckInterval[\"Check Interval Reached?\"] CheckInterval --> CheckService[\"Check Service Availability\"] CheckService --> UpdateCache[\"Update Cache\"] UpdateCache --> StatusChanged[\"Status Changed?\"] StatusChanged -- Yes --> StatusEvent[\"Status Change Event\"] StatusEvent --> UpdateLogs[\"Update Logs & Send Alerts\"] StatusChanged -- No --> Wait[\"Wait for Next Check\"]","title":"10.2 Service Monitoring Flowchart"},{"location":"service-availability/processing-diagrams/#103-failover-process-diagram","text":"flowchart TD Request[\"Request Received\"] --> ServiceAvailable[\"Service Available?\"] ServiceAvailable -- Yes --> RateLimited[\"Service Rate-Limited?\"] ServiceAvailable -- No --> TryNext[\"Try Next Service\"] RateLimited -- No --> ProcessPrimary[\"Process with Primary Service\"] TryNext --> AnyAvailable[\"Any Service Available?\"] AnyAvailable -- No --> ReturnError[\"Return Error\\nUse Client Fallback\"] AnyAvailable -- Yes --> ProcessAvailable[\"Process with\\nAvailable Service\"]","title":"10.3 Failover Process Diagram"},{"location":"service-availability/processing-diagrams/#104-rate-limit-monitoring-diagram","text":"flowchart TD TrackAPI[\"Track API Request\"] --> ResetPeriod[\"Reset Period Elapsed?\"] ResetPeriod -- Yes --> ResetCounters[\"Reset Counters\"] ResetCounters --> IncrementCounters[\"Increment Counters\"] TrackAPI --> IncrementCounters IncrementCounters --> ApproachingLimit[\"Approaching Limit?\"] ApproachingLimit -- Yes --> LogWarning[\"Log Warning\\nPrepare Fallback\"] ApproachingLimit -- No --> ContinueNormal[\"Continue Normal Operation\"]","title":"10.4 Rate Limit Monitoring Diagram"},{"location":"service-availability/processing-diagrams/#105-recovery-detection-process","text":"flowchart TD Unavailable[\"Service Unavailable\"] --> HealthCheck[\"Periodic Health Check\"] HealthCheck --> Recovered[\"Service Recovered?\"] Recovered -- No --> ContinueFallback[\"Continue Using Fallback\"] Recovered -- Yes --> LogRecovery[\"Log Recovery\\nUpdate Status\"] LogRecovery --> ResumePreferred[\"Resume Using Preferred Service\"]","title":"10.5 Recovery Detection Process"},{"location":"service-availability/processing-diagrams/#106-user-experience-flow","text":"flowchart TD UserQuery[\"User Submits Query\"] --> FrontendProcess[\"Frontend Processes Input\"] FrontendProcess --> APIRequest[\"API Request to Server\"] APIRequest --> ServerAvailable[\"Server Available?\"] ServerAvailable -- No --> ClientFallback[\"Client-side Fallback Activated\"] ClientFallback --> ShowError[\"Show Error Message with Limited Mode\"] ServerAvailable -- Yes --> UsingFallback[\"Service Using Fallback?\"] UsingFallback -- Yes --> NotifyUser[\"Notify User of Service Limitations\"] UsingFallback -- No --> NormalResponse[\"Normal Response Processing\"]","title":"10.6 User Experience Flow"},{"location":"service-availability/processing-diagrams/#107-c4-context-diagram","text":"C4Context title System Context diagram for Opossum Search Person(user, \"User\", \"A user of the Opossum Search system\") Enterprise_Boundary(b0, \"Opossum Search System\") { System(searchSystem, \"Opossum Search System\", \"Provides search functionality with multiple model providers\") System_Ext(geminiAPI, \"Gemini API\", \"External large language model provider\") System_Ext(ollamaSystem, \"Ollama\", \"Local large language model hosting\") System_Ext(transformersLib, \"Transformers\", \"Local machine learning library\") } Rel(user, searchSystem, \"Submits search queries to\") Rel(searchSystem, geminiAPI, \"Uses for processing when available\") Rel(searchSystem, ollamaSystem, \"Falls back to when Gemini is unavailable\") Rel(searchSystem, transformersLib, \"Uses as final fallback option\")","title":"10.7 C4 Context Diagram"},{"location":"service-availability/quality-requirements/","text":"2. Quality Requirements 2.1 Availability Requirements Service Uptime Target Measurement Period Critical Hours Opossum Search Application 99.5% Monthly 24/7 Gemini API 98% Monthly Business hours Ollama Service 95% Weekly Business hours Transformers Fallback 99.9% Monthly 24/7 2.2 Performance Requirements Metric Target Description Service Check Response Time < 500ms Maximum time for a single service availability check Failover Detection Time < 2s Time to detect a service failure and initiate failover Failover Completion Time < 5s Time to complete transition to alternative service Service Status Cache Validity 30s Maximum age of cached service status information 2.3 Recovery Time Objectives Scenario Recovery Time Objective (RTO) Recovery Point Objective (RPO) Gemini API Unavailable Immediate failover to Ollama No data loss Ollama Service Failure < 1 minute for auto-restart, immediate failover to Transformers No data loss All Remote Services Down < 10 seconds to activate offline mode Potential loss of latest model updates 2.4 Logging and Monitoring Requirements Requirement Description Status Change Logging All service status changes must be logged with timestamp and reason Rate Limit Tracking Gemini API usage must be tracked with 99.99% accuracy Critical Alerts Service outages must trigger alerts within 30 seconds Availability Reports System must generate daily availability reports 2.5 Quality Verification Verification Method Frequency Responsibility Availability Tests Daily automated tests CI/CD Pipeline Failover Tests Weekly Development Team Recovery Procedure Tests Monthly Operations Team Load Testing Quarterly QA Team","title":"Quality Requirements"},{"location":"service-availability/quality-requirements/#2-quality-requirements","text":"","title":"2. Quality Requirements"},{"location":"service-availability/quality-requirements/#21-availability-requirements","text":"Service Uptime Target Measurement Period Critical Hours Opossum Search Application 99.5% Monthly 24/7 Gemini API 98% Monthly Business hours Ollama Service 95% Weekly Business hours Transformers Fallback 99.9% Monthly 24/7","title":"2.1 Availability Requirements"},{"location":"service-availability/quality-requirements/#22-performance-requirements","text":"Metric Target Description Service Check Response Time < 500ms Maximum time for a single service availability check Failover Detection Time < 2s Time to detect a service failure and initiate failover Failover Completion Time < 5s Time to complete transition to alternative service Service Status Cache Validity 30s Maximum age of cached service status information","title":"2.2 Performance Requirements"},{"location":"service-availability/quality-requirements/#23-recovery-time-objectives","text":"Scenario Recovery Time Objective (RTO) Recovery Point Objective (RPO) Gemini API Unavailable Immediate failover to Ollama No data loss Ollama Service Failure < 1 minute for auto-restart, immediate failover to Transformers No data loss All Remote Services Down < 10 seconds to activate offline mode Potential loss of latest model updates","title":"2.3 Recovery Time Objectives"},{"location":"service-availability/quality-requirements/#24-logging-and-monitoring-requirements","text":"Requirement Description Status Change Logging All service status changes must be logged with timestamp and reason Rate Limit Tracking Gemini API usage must be tracked with 99.99% accuracy Critical Alerts Service outages must trigger alerts within 30 seconds Availability Reports System must generate daily availability reports","title":"2.4 Logging and Monitoring Requirements"},{"location":"service-availability/quality-requirements/#25-quality-verification","text":"Verification Method Frequency Responsibility Availability Tests Daily automated tests CI/CD Pipeline Failover Tests Weekly Development Team Recovery Procedure Tests Monthly Operations Team Load Testing Quarterly QA Team","title":"2.5 Quality Verification"},{"location":"service-availability/rate-limiting-throttling/","text":"6. Rate Limiting and Throttling 6.1 Rate Limit Policies Service Rate Limit Type Quota Reset Period Priority Handling Gemini API API Calls 60 per minute Minute High-value queries prioritized Gemini API Daily Usage 60,000 per day 24 hours Resource allocation based on time of day Ollama Local Resource CPU/GPU dependent N/A Queue-based with timeout Transformers Local Resource Memory/CPU dependent N/A Simplified models for high load 6.2 Detection Mechanisms Limit Type Detection Method Response Code Handling Strategy Pre-emptive Counter tracking N/A Redirect before limit reached Reactive HTTP 429 response 429 Too Many Requests Immediate failover to alternative service Quota Exceeded HTTP 403 response 403 Forbidden Temporary service downgrade Resource Exhaustion Exception/timeout Various Scale down model complexity 6.3 Request Management Approach Implementation Benefit Request Queuing In-memory FIFO queue with priority Prevents request loss during high load Request Coalescing Combine similar requests Reduces total API calls Request Prioritization User interaction > Background tasks Maintains responsive UX Adaptive TTL Dynamic cache lifetime based on load Reduces API calls during peak 6.4 Throttling Implementation class RateLimitManager: def __init__(self): self.minute_usage = 0 self.daily_usage = 0 self.last_minute_reset = datetime.now() self.last_daily_reset = datetime.now() self.request_queue = asyncio.Queue() async def track_request(self): \"\"\"Track a new request against rate limits\"\"\" current_time = datetime.now() # Reset counters if needed if (current_time - self.last_minute_reset).seconds >= 60: self.minute_usage = 0 self.last_minute_reset = current_time if (current_time - self.last_daily_reset).days >= 1: self.daily_usage = 0 self.last_daily_reset = current_time # Increment counters self.minute_usage += 1 self.daily_usage += 1 async def can_process_request(self): \"\"\"Check if request can be processed within rate limits\"\"\" return self.minute_usage < 58 # Buffer of 2 requests async def process_or_queue(self, request_func, *args): \"\"\"Process request or queue it based on rate limits\"\"\" if await self.can_process_request(): await self.track_request() return await request_func(*args) else: # Queue the request or fail over return await self.handle_rate_limit(*args) 6.5 Client-Side Adaptation Condition Client Behavior User Experience Server Rate Limited Switch to fallback simulation \"Using simplified mode temporarily\" Approaching Limits Batch requests Normal with slight delay Normal Operation Direct API access Full functionality Extended Outage Local-only operation Reduced capabilities with notification 6.6 Balance and Optimization Strategies Strategy Implementation Effect Time-of-day Allocation Reserve quota for peak hours Consistent availability during business hours Request Complexity Analysis Measure token count before sending Route complex queries to appropriate backend Adaptive Backoff Exponential delay with jitter Graceful recovery during service degradation Quota Forecasting Predictive usage modeling Proactive service switching before limits reached 6.7 Monitoring and Alerts Metric Threshold Alert Type Recipient Minute Usage >80% of limit Warning Logs Minute Usage >95% of limit Critical Operations Team Daily Usage >90% of limit Warning Operations Team Queue Size >20 requests Warning Logs Queue Size >50 requests Critical Operations Team Queue Wait Time >5 seconds Warning Logs, User Notification","title":"Rate Limiting"},{"location":"service-availability/rate-limiting-throttling/#6-rate-limiting-and-throttling","text":"","title":"6. Rate Limiting and Throttling"},{"location":"service-availability/rate-limiting-throttling/#61-rate-limit-policies","text":"Service Rate Limit Type Quota Reset Period Priority Handling Gemini API API Calls 60 per minute Minute High-value queries prioritized Gemini API Daily Usage 60,000 per day 24 hours Resource allocation based on time of day Ollama Local Resource CPU/GPU dependent N/A Queue-based with timeout Transformers Local Resource Memory/CPU dependent N/A Simplified models for high load","title":"6.1 Rate Limit Policies"},{"location":"service-availability/rate-limiting-throttling/#62-detection-mechanisms","text":"Limit Type Detection Method Response Code Handling Strategy Pre-emptive Counter tracking N/A Redirect before limit reached Reactive HTTP 429 response 429 Too Many Requests Immediate failover to alternative service Quota Exceeded HTTP 403 response 403 Forbidden Temporary service downgrade Resource Exhaustion Exception/timeout Various Scale down model complexity","title":"6.2 Detection Mechanisms"},{"location":"service-availability/rate-limiting-throttling/#63-request-management","text":"Approach Implementation Benefit Request Queuing In-memory FIFO queue with priority Prevents request loss during high load Request Coalescing Combine similar requests Reduces total API calls Request Prioritization User interaction > Background tasks Maintains responsive UX Adaptive TTL Dynamic cache lifetime based on load Reduces API calls during peak","title":"6.3 Request Management"},{"location":"service-availability/rate-limiting-throttling/#64-throttling-implementation","text":"class RateLimitManager: def __init__(self): self.minute_usage = 0 self.daily_usage = 0 self.last_minute_reset = datetime.now() self.last_daily_reset = datetime.now() self.request_queue = asyncio.Queue() async def track_request(self): \"\"\"Track a new request against rate limits\"\"\" current_time = datetime.now() # Reset counters if needed if (current_time - self.last_minute_reset).seconds >= 60: self.minute_usage = 0 self.last_minute_reset = current_time if (current_time - self.last_daily_reset).days >= 1: self.daily_usage = 0 self.last_daily_reset = current_time # Increment counters self.minute_usage += 1 self.daily_usage += 1 async def can_process_request(self): \"\"\"Check if request can be processed within rate limits\"\"\" return self.minute_usage < 58 # Buffer of 2 requests async def process_or_queue(self, request_func, *args): \"\"\"Process request or queue it based on rate limits\"\"\" if await self.can_process_request(): await self.track_request() return await request_func(*args) else: # Queue the request or fail over return await self.handle_rate_limit(*args)","title":"6.4 Throttling Implementation"},{"location":"service-availability/rate-limiting-throttling/#65-client-side-adaptation","text":"Condition Client Behavior User Experience Server Rate Limited Switch to fallback simulation \"Using simplified mode temporarily\" Approaching Limits Batch requests Normal with slight delay Normal Operation Direct API access Full functionality Extended Outage Local-only operation Reduced capabilities with notification","title":"6.5 Client-Side Adaptation"},{"location":"service-availability/rate-limiting-throttling/#66-balance-and-optimization-strategies","text":"Strategy Implementation Effect Time-of-day Allocation Reserve quota for peak hours Consistent availability during business hours Request Complexity Analysis Measure token count before sending Route complex queries to appropriate backend Adaptive Backoff Exponential delay with jitter Graceful recovery during service degradation Quota Forecasting Predictive usage modeling Proactive service switching before limits reached","title":"6.6 Balance and Optimization Strategies"},{"location":"service-availability/rate-limiting-throttling/#67-monitoring-and-alerts","text":"Metric Threshold Alert Type Recipient Minute Usage >80% of limit Warning Logs Minute Usage >95% of limit Critical Operations Team Daily Usage >90% of limit Warning Operations Team Queue Size >20 requests Warning Logs Queue Size >50 requests Critical Operations Team Queue Wait Time >5 seconds Warning Logs, User Notification","title":"6.7 Monitoring and Alerts"},{"location":"service-availability/service-outage/","text":"5. Error Handling and Recovery 5.1 Error Detection and Classification Error Type Detection Method Priority Example API Connection Failure Request timeout or HTTP error High Gemini API unreachable Rate Limit Reached HTTP 429 or quota tracking High Gemini API quota exceeded Authentication Failure HTTP 401/403 response High Invalid or expired API key Local Service Unreachable Socket connection failure Medium Ollama service not running Model Loading Failure Exception during model initialization Medium Insufficient resources for Transformers Slow Response Response time exceeding threshold Low Degraded performance warning 5.2 Failover Strategy From Service To Service Trigger Transition Time Gemini API \u2192 Ollama Connection failure, rate limit, or auth error Immediate < 2s Ollama \u2192 Transformers Connection failure or initialization error Immediate < 5s Any \u2192 Client-side Fallback All server services unavailable After 3 retries < 10s 5.3 Recovery Procedures Service Automatic Recovery Manual Recovery Steps Gemini API Periodic availability checks to detect when service is restored 1. Verify API key validity 2. Check quota status 3. Test connectivity to API endpoint 4. Update API configuration if needed Ollama Restart attempt after 60s of unavailability 1. Check local service process 2. Restart Ollama service 3. Verify model availability 4. Check GPU utilization if performance issues Transformers Model reloading attempt if initialization fails 1. Verify model files exist 2. Check available RAM 3. Consider loading smaller model variant 4. Update model files if corrupted 5.4 Error Communication Audience Error Information Delivery Method End Users General error with degraded capability notice UI message: \"Using alternative model due to service availability\" Developers Detailed error including exception trace and service status Application logs with ERROR level Operations Service status changes and recovery attempts Logs and monitoring alerts 5.5 Resilience Mechanisms Mechanism Purpose Implementation Circuit Breaker Prevent repeated calls to failing services Exponential backoff with jitter Request Caching Serve previous responses during outages In-memory cache with TTL Client-side Fallback Provide degraded functionality when server is unavailable JavaScript simulation mode in UI Service Prioritization Route requests to highest capability available service Service ranking with availability checks Graceful Degradation Maintain core functionality with limited capabilities Feature flags based on available services 5.6 Recovery Monitoring Recovery Metric Measurement Threshold Action Recovery Time Time from failure to service restoration > RTO Alert operations team Failed Recovery Attempts Count of unsuccessful recovery attempts > 3 Escalate to manual intervention Failover Frequency Number of failovers in 24h period > 5 Investigate root cause Performance After Recovery Response time compared to baseline > 150% of baseline Flag for optimization","title":"Error Handling"},{"location":"service-availability/service-outage/#5-error-handling-and-recovery","text":"","title":"5. Error Handling and Recovery"},{"location":"service-availability/service-outage/#51-error-detection-and-classification","text":"Error Type Detection Method Priority Example API Connection Failure Request timeout or HTTP error High Gemini API unreachable Rate Limit Reached HTTP 429 or quota tracking High Gemini API quota exceeded Authentication Failure HTTP 401/403 response High Invalid or expired API key Local Service Unreachable Socket connection failure Medium Ollama service not running Model Loading Failure Exception during model initialization Medium Insufficient resources for Transformers Slow Response Response time exceeding threshold Low Degraded performance warning","title":"5.1 Error Detection and Classification"},{"location":"service-availability/service-outage/#52-failover-strategy","text":"From Service To Service Trigger Transition Time Gemini API \u2192 Ollama Connection failure, rate limit, or auth error Immediate < 2s Ollama \u2192 Transformers Connection failure or initialization error Immediate < 5s Any \u2192 Client-side Fallback All server services unavailable After 3 retries < 10s","title":"5.2 Failover Strategy"},{"location":"service-availability/service-outage/#53-recovery-procedures","text":"Service Automatic Recovery Manual Recovery Steps Gemini API Periodic availability checks to detect when service is restored 1. Verify API key validity 2. Check quota status 3. Test connectivity to API endpoint 4. Update API configuration if needed Ollama Restart attempt after 60s of unavailability 1. Check local service process 2. Restart Ollama service 3. Verify model availability 4. Check GPU utilization if performance issues Transformers Model reloading attempt if initialization fails 1. Verify model files exist 2. Check available RAM 3. Consider loading smaller model variant 4. Update model files if corrupted","title":"5.3 Recovery Procedures"},{"location":"service-availability/service-outage/#54-error-communication","text":"Audience Error Information Delivery Method End Users General error with degraded capability notice UI message: \"Using alternative model due to service availability\" Developers Detailed error including exception trace and service status Application logs with ERROR level Operations Service status changes and recovery attempts Logs and monitoring alerts","title":"5.4 Error Communication"},{"location":"service-availability/service-outage/#55-resilience-mechanisms","text":"Mechanism Purpose Implementation Circuit Breaker Prevent repeated calls to failing services Exponential backoff with jitter Request Caching Serve previous responses during outages In-memory cache with TTL Client-side Fallback Provide degraded functionality when server is unavailable JavaScript simulation mode in UI Service Prioritization Route requests to highest capability available service Service ranking with availability checks Graceful Degradation Maintain core functionality with limited capabilities Feature flags based on available services","title":"5.5 Resilience Mechanisms"},{"location":"service-availability/service-outage/#56-recovery-monitoring","text":"Recovery Metric Measurement Threshold Action Recovery Time Time from failure to service restoration > RTO Alert operations team Failed Recovery Attempts Count of unsuccessful recovery attempts > 3 Escalate to manual intervention Failover Frequency Number of failovers in 24h period > 5 Investigate root cause Performance After Recovery Response time compared to baseline > 150% of baseline Flag for optimization","title":"5.6 Recovery Monitoring"},{"location":"service-availability/testing-validation/","text":"9. Testing and Validation - Service Availability 9.1 Testing Strategy Test Type Purpose Frequency Implementation Unit Tests Verify individual components function correctly Per commit Pytest for Python components Integration Tests Verify service interaction and failover logic Daily Automated test suite with service mocks End-to-End Tests Verify complete system behavior Weekly Real-world scenarios with actual services Chaos Tests Verify resilience during unexpected failures Monthly Random service disruption testing Load Tests Verify behavior under high throughput Quarterly Simulated high volume request patterns 9.2 Test Scenarios Scenario Test Case Validation Criteria Gemini Unavailability Simulate API timeout Successful failover to Ollama within 2s Rate Limit Exceeded Generate high request volume Preemptive failover before 429 error Authentication Failure Use invalid API key Correct error handling and failover Intermittent Failures Random request failures Circuit breaker activation after threshold Slow Response Delayed API responses Timeout detection and service degradation Recovery Detection Restore service after outage Return to primary service within check interval 9.3 Validation Methods Method Description Tools Metrics Availability Metrics Measure uptime percentage Custom metrics collector 99.5% target uptime Failover Success Rate Measure successful transitions Test harness logs >99% success target Response Time Validation Measure end-to-end latency Request timing <5s during failover User Experience Assessment Evaluate quality of fallback responses Subjective scoring Minimal degradation Recovery Time Validation Measure time to restore optimal service Test harness logs Within RTO targets 9.4 Testing Infrastructure Component Purpose Implementation Mock Services Simulate API responses and failures Pytest fixtures and mock HTTP servers Rate Limit Simulator Test behavior near quota limits Counter manipulation and response code injection Network Condition Simulator Test with varied connectivity Proxy with configurable delays and failures Test Harness Coordinate and execute test suites Pytest with custom plugins CI/CD Integration Automate testing on changes GitHub Actions workflows 9.5 Testing Implementation # Example test case for failover behavior import pytest import asyncio from unittest.mock import patch, MagicMock class TestServiceFailover: @pytest.mark.asyncio async def test_gemini_to_ollama_failover(self, availability_manager, service_router): # Arrange - Mock Gemini as unavailable with patch.object(availability_manager, 'get_available_services') as mock_get: mock_get.return_value = {\"ollama\", \"transformers\"} # Gemini not available # Act - Attempt to route a request result = await service_router.route_request({\"query\": \"test question\"}) # Assert - Request was handled by Ollama assert result[\"fallback_used\"] == \"ollama\" assert \"response\" in result 9.6 Validation Dashboard Metric Visualization Threshold Alerts Service Uptime Time-series graph <99.5% Email to operations Failover Events Count and distribution >5 per day Slack notification Average Response Time Time-series by service >2s baseline Warning in dashboard Error Rate Percentage by service >1% Critical alert Fallback Distribution Pie chart of service usage >20% non-primary Weekly report 9.7 Continuous Testing Practice Implementation Frequency Responsible Team Automated Test Suite Full test coverage in CI pipeline Every PR Development Synthetic Monitoring Regular health checks from external locations Every 5 minutes Operations Regression Testing Verify fixed issues don't recur Every release QA Scheduled Chaos Tests Planned service disruptions Weekly off-hours SRE User Journey Tests End-to-end experience validation Bi-weekly QA","title":"Testing and Validation"},{"location":"service-availability/testing-validation/#9-testing-and-validation-service-availability","text":"","title":"9. Testing and Validation - Service Availability"},{"location":"service-availability/testing-validation/#91-testing-strategy","text":"Test Type Purpose Frequency Implementation Unit Tests Verify individual components function correctly Per commit Pytest for Python components Integration Tests Verify service interaction and failover logic Daily Automated test suite with service mocks End-to-End Tests Verify complete system behavior Weekly Real-world scenarios with actual services Chaos Tests Verify resilience during unexpected failures Monthly Random service disruption testing Load Tests Verify behavior under high throughput Quarterly Simulated high volume request patterns","title":"9.1 Testing Strategy"},{"location":"service-availability/testing-validation/#92-test-scenarios","text":"Scenario Test Case Validation Criteria Gemini Unavailability Simulate API timeout Successful failover to Ollama within 2s Rate Limit Exceeded Generate high request volume Preemptive failover before 429 error Authentication Failure Use invalid API key Correct error handling and failover Intermittent Failures Random request failures Circuit breaker activation after threshold Slow Response Delayed API responses Timeout detection and service degradation Recovery Detection Restore service after outage Return to primary service within check interval","title":"9.2 Test Scenarios"},{"location":"service-availability/testing-validation/#93-validation-methods","text":"Method Description Tools Metrics Availability Metrics Measure uptime percentage Custom metrics collector 99.5% target uptime Failover Success Rate Measure successful transitions Test harness logs >99% success target Response Time Validation Measure end-to-end latency Request timing <5s during failover User Experience Assessment Evaluate quality of fallback responses Subjective scoring Minimal degradation Recovery Time Validation Measure time to restore optimal service Test harness logs Within RTO targets","title":"9.3 Validation Methods"},{"location":"service-availability/testing-validation/#94-testing-infrastructure","text":"Component Purpose Implementation Mock Services Simulate API responses and failures Pytest fixtures and mock HTTP servers Rate Limit Simulator Test behavior near quota limits Counter manipulation and response code injection Network Condition Simulator Test with varied connectivity Proxy with configurable delays and failures Test Harness Coordinate and execute test suites Pytest with custom plugins CI/CD Integration Automate testing on changes GitHub Actions workflows","title":"9.4 Testing Infrastructure"},{"location":"service-availability/testing-validation/#95-testing-implementation","text":"# Example test case for failover behavior import pytest import asyncio from unittest.mock import patch, MagicMock class TestServiceFailover: @pytest.mark.asyncio async def test_gemini_to_ollama_failover(self, availability_manager, service_router): # Arrange - Mock Gemini as unavailable with patch.object(availability_manager, 'get_available_services') as mock_get: mock_get.return_value = {\"ollama\", \"transformers\"} # Gemini not available # Act - Attempt to route a request result = await service_router.route_request({\"query\": \"test question\"}) # Assert - Request was handled by Ollama assert result[\"fallback_used\"] == \"ollama\" assert \"response\" in result","title":"9.5 Testing Implementation"},{"location":"service-availability/testing-validation/#96-validation-dashboard","text":"Metric Visualization Threshold Alerts Service Uptime Time-series graph <99.5% Email to operations Failover Events Count and distribution >5 per day Slack notification Average Response Time Time-series by service >2s baseline Warning in dashboard Error Rate Percentage by service >1% Critical alert Fallback Distribution Pie chart of service usage >20% non-primary Weekly report","title":"9.6 Validation Dashboard"},{"location":"service-availability/testing-validation/#97-continuous-testing","text":"Practice Implementation Frequency Responsible Team Automated Test Suite Full test coverage in CI pipeline Every PR Development Synthetic Monitoring Regular health checks from external locations Every 5 minutes Operations Regression Testing Verify fixed issues don't recur Every release QA Scheduled Chaos Tests Planned service disruptions Weekly off-hours SRE User Journey Tests End-to-end experience validation Bi-weekly QA","title":"9.7 Continuous Testing"}]}